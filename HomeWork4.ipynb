{
 "cells": [
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SmartLab project 4\n",
    "### transfer learning"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "I couldn't find any open image downloader script, all of them had outdated image links. Therefore I downloaded pictures directly from google with [this script](https://github.com/hardikvasa/google-images-download) and made the quality check myself"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications.vgg19 import VGG19\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Flatten\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_height= 224\n",
    "img_width= 224"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = 'hw4'\n",
    "train_dir = os.path.join( base_dir, 'train')\n",
    "validation_dir = os.path.join( base_dir, 'validation')\n",
    "test_dir = os.path.join( base_dir, 'test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = VGG19( weights = 'imagenet', include_top = False)\n",
    "\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Flatten()(x)\n",
    "x = Dense( 1024, activation = 'relu')(x)\n",
    "predictions = Dense( 3, activation = 'softmax')(x)\n",
    "\n",
    "model = Model( inputs = base_model.input, outputs = predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "model.compile( optimizer = 'adam', metrics = [ 'accuracy'], loss = 'categorical_crossentropy')"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Due to the original VGG19 model my only image preprocess method is featurewise centering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Found 1200 images belonging to 3 classes.\nFound 300 images belonging to 3 classes.\nFound 300 images belonging to 3 classes.\n"
    }
   ],
   "source": [
    "image_datagen = ImageDataGenerator( featurewise_center = True)\n",
    "\n",
    "train_generator = image_datagen.flow_from_directory( train_dir, target_size = ( img_height, img_width), batch_size=20)\n",
    "validation_generator = image_datagen.flow_from_directory( validation_dir, target_size = ( img_height, img_width), batch_size=20)\n",
    "test_generator = image_datagen.flow_from_directory( validation_dir, target_size = ( img_height, img_width), batch_size=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": "C:\\Python\\Python37\\lib\\site-packages\\keras_preprocessing\\image\\image_data_generator.py:716: UserWarning: This ImageDataGenerator specifies `featurewise_center`, but it hasn't been fit on any training data. Fit it first by calling `.fit(numpy_data)`.\n  warnings.warn('This ImageDataGenerator specifies '\nEpoch 1/3\n15/15 [==============================] - 232s 15s/step - loss: 0.2167 - acc: 0.9633\n60/60 [==============================] - 851s 14s/step - loss: 0.7938 - acc: 0.9100 - val_loss: 0.2167 - val_acc: 0.9633\nEpoch 2/3\n15/15 [==============================] - 233s 16s/step - loss: 0.4017 - acc: 0.9400\n60/60 [==============================] - 1036s 17s/step - loss: 0.1367 - acc: 0.9800 - val_loss: 0.4017 - val_acc: 0.9400\nEpoch 3/3\n15/15 [==============================] - 226s 15s/step - loss: 0.0997 - acc: 0.9733\n60/60 [==============================] - 1039s 17s/step - loss: 0.1094 - acc: 0.9775 - val_loss: 0.0997 - val_acc: 0.9733\n"
    },
    {
     "data": {
      "text/plain": "<tensorflow.python.keras.callbacks.History at 0x17bb085cbc8>"
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit_generator( train_generator, validation_data = validation_generator, epochs=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "A VGG19 konvolúciós rétegei:\n0 input_5\n1 block1_conv1\n2 block1_conv2\n3 block1_pool\n4 block2_conv1\n5 block2_conv2\n6 block2_pool\n7 block3_conv1\n8 block3_conv2\n9 block3_conv3\n10 block3_conv4\n11 block3_pool\n12 block4_conv1\n13 block4_conv2\n14 block4_conv3\n15 block4_conv4\n16 block4_pool\n17 block5_conv1\n18 block5_conv2\n19 block5_conv3\n20 block5_conv4\n21 block5_pool\n"
    }
   ],
   "source": [
    "print( \"A VGG19 konvolúciós rétegei:\")\n",
    "for i, layer in enumerate( base_model.layers):\n",
    "    print( i, layer.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in model.layers[ :12]:\n",
    "       layer.trainable = False\n",
    "for layer in model.layers[ 12:]:\n",
    "       layer.trainable = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile( optimizer = 'adam', metrics=[ 'accuracy'], loss = 'categorical_crossentropy')"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "My computer isn't strong enough to run the training (freeze every time) but it works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Epoch 1/3\n14/15 [===========================>..] - ETA: 14s - loss: 10.8221 - acc: 0.3286"
    }
   ],
   "source": [
    "model.fit_generator( train_generator, validation_data = validation_generator, validation_steps=10, epochs=3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
